{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5b4734a",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cda1ea98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Embedding,LSTM,Dense,Flatten,Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496df470",
   "metadata": {},
   "source": [
    "## Data Loading and Understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ac644f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load teh csv data to a pandas dataframe\n",
    "\n",
    "data=pd.read_csv(\"Twitter_Data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1eb5cb7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cb774db0d1</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>549e992a42</td>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>Sooo SAD</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>088c60f138</td>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>bullying me</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9642c003ef</td>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>leave me alone</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>358bd9e861</td>\n",
       "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
       "      <td>Sons of ****,</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                               text  \\\n",
       "0  cb774db0d1                I`d have responded, if I were going   \n",
       "1  549e992a42      Sooo SAD I will miss you here in San Diego!!!   \n",
       "2  088c60f138                          my boss is bullying me...   \n",
       "3  9642c003ef                     what interview! leave me alone   \n",
       "4  358bd9e861   Sons of ****, why couldn`t they put them on t...   \n",
       "\n",
       "                         selected_text sentiment  \n",
       "0  I`d have responded, if I were going   neutral  \n",
       "1                             Sooo SAD  negative  \n",
       "2                          bullying me  negative  \n",
       "3                       leave me alone  negative  \n",
       "4                        Sons of ****,  negative  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First 5 rows of the dataset\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c761db19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27476</th>\n",
       "      <td>4eac33d1c0</td>\n",
       "      <td>wish we could come see u on Denver  husband l...</td>\n",
       "      <td>d lost</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27477</th>\n",
       "      <td>4f4c4fc327</td>\n",
       "      <td>I`ve wondered about rake to.  The client has ...</td>\n",
       "      <td>, don`t force</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27478</th>\n",
       "      <td>f67aae2310</td>\n",
       "      <td>Yay good for both of you. Enjoy the break - y...</td>\n",
       "      <td>Yay good for both of you.</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27479</th>\n",
       "      <td>ed167662a5</td>\n",
       "      <td>But it was worth it  ****.</td>\n",
       "      <td>But it was worth it  ****.</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27480</th>\n",
       "      <td>6f7127d9d7</td>\n",
       "      <td>All this flirting going on - The ATG smiles...</td>\n",
       "      <td>All this flirting going on - The ATG smiles. Y...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           textID                                               text  \\\n",
       "27476  4eac33d1c0   wish we could come see u on Denver  husband l...   \n",
       "27477  4f4c4fc327   I`ve wondered about rake to.  The client has ...   \n",
       "27478  f67aae2310   Yay good for both of you. Enjoy the break - y...   \n",
       "27479  ed167662a5                         But it was worth it  ****.   \n",
       "27480  6f7127d9d7     All this flirting going on - The ATG smiles...   \n",
       "\n",
       "                                           selected_text sentiment  \n",
       "27476                                             d lost  negative  \n",
       "27477                                      , don`t force  negative  \n",
       "27478                          Yay good for both of you.  positive  \n",
       "27479                         But it was worth it  ****.  positive  \n",
       "27480  All this flirting going on - The ATG smiles. Y...   neutral  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Last 5 rows of the dataset\n",
    "\n",
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab76b8d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27481, 4)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#number of row and columns\n",
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7c80a6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 27481 entries, 0 to 27480\n",
      "Data columns (total 4 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   textID         27481 non-null  object\n",
      " 1   text           27480 non-null  object\n",
      " 2   selected_text  27480 non-null  object\n",
      " 3   sentiment      27481 non-null  object\n",
      "dtypes: object(4)\n",
      "memory usage: 858.9+ KB\n"
     ]
    }
   ],
   "source": [
    "# Dataset information\n",
    "\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a9f0b2",
   "metadata": {},
   "source": [
    "## Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1405c028",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chang the data type for text\n",
    "\n",
    "data['text']=data['text'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6fb9fab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                      I`d have responded, if I were going\n",
       "1            Sooo SAD I will miss you here in San Diego!!!\n",
       "2                                my boss is bullying me...\n",
       "3                           what interview! leave me alone\n",
       "4         Sons of ****, why couldn`t they put them on t...\n",
       "                               ...                        \n",
       "27476     wish we could come see u on Denver  husband l...\n",
       "27477     I`ve wondered about rake to.  The client has ...\n",
       "27478     Yay good for both of you. Enjoy the break - y...\n",
       "27479                           But it was worth it  ****.\n",
       "27480       All this flirting going on - The ATG smiles...\n",
       "Name: text, Length: 27481, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b35e153d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleans 'text' by removing non-alphabetical characters and converting to lowercase\n",
    "\n",
    "data['clean_text']= data['text'].str.replace('[^a-zA-Z\\s]','',regex=True).str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "201034ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                        id have responded if i were going\n",
       "1               sooo sad i will miss you here in san diego\n",
       "2                                   my boss is bullying me\n",
       "3                            what interview leave me alone\n",
       "4         sons of  why couldnt they put them on the rel...\n",
       "                               ...                        \n",
       "27476     wish we could come see u on denver  husband l...\n",
       "27477     ive wondered about rake to  the client has ma...\n",
       "27478     yay good for both of you enjoy the break  you...\n",
       "27479                                but it was worth it  \n",
       "27480       all this flirting going on  the atg smiles ...\n",
       "Name: clean_text, Length: 27481, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieves the 'clean_text' column\n",
    "\n",
    "data['clean_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b65d7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drops the 'textID' and 'selected_text' columns from the DataFrame in place\n",
    "\n",
    "data.drop(columns=['textID','selected_text'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6eed65d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "      <td>id have responded if i were going</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>negative</td>\n",
       "      <td>sooo sad i will miss you here in san diego</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>negative</td>\n",
       "      <td>my boss is bullying me</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>negative</td>\n",
       "      <td>what interview leave me alone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
       "      <td>negative</td>\n",
       "      <td>sons of  why couldnt they put them on the rel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27476</th>\n",
       "      <td>wish we could come see u on Denver  husband l...</td>\n",
       "      <td>negative</td>\n",
       "      <td>wish we could come see u on denver  husband l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27477</th>\n",
       "      <td>I`ve wondered about rake to.  The client has ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>ive wondered about rake to  the client has ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27478</th>\n",
       "      <td>Yay good for both of you. Enjoy the break - y...</td>\n",
       "      <td>positive</td>\n",
       "      <td>yay good for both of you enjoy the break  you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27479</th>\n",
       "      <td>But it was worth it  ****.</td>\n",
       "      <td>positive</td>\n",
       "      <td>but it was worth it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27480</th>\n",
       "      <td>All this flirting going on - The ATG smiles...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>all this flirting going on  the atg smiles ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27481 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text sentiment  \\\n",
       "0                    I`d have responded, if I were going   neutral   \n",
       "1          Sooo SAD I will miss you here in San Diego!!!  negative   \n",
       "2                              my boss is bullying me...  negative   \n",
       "3                         what interview! leave me alone  negative   \n",
       "4       Sons of ****, why couldn`t they put them on t...  negative   \n",
       "...                                                  ...       ...   \n",
       "27476   wish we could come see u on Denver  husband l...  negative   \n",
       "27477   I`ve wondered about rake to.  The client has ...  negative   \n",
       "27478   Yay good for both of you. Enjoy the break - y...  positive   \n",
       "27479                         But it was worth it  ****.  positive   \n",
       "27480     All this flirting going on - The ATG smiles...   neutral   \n",
       "\n",
       "                                              clean_text  \n",
       "0                      id have responded if i were going  \n",
       "1             sooo sad i will miss you here in san diego  \n",
       "2                                 my boss is bullying me  \n",
       "3                          what interview leave me alone  \n",
       "4       sons of  why couldnt they put them on the rel...  \n",
       "...                                                  ...  \n",
       "27476   wish we could come see u on denver  husband l...  \n",
       "27477   ive wondered about rake to  the client has ma...  \n",
       "27478   yay good for both of you enjoy the break  you...  \n",
       "27479                              but it was worth it    \n",
       "27480     all this flirting going on  the atg smiles ...  \n",
       "\n",
       "[27481 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7a0004d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assigns the 'clean_text' column to variable 'x' and 'sentiment' column to variable 'y'\n",
    "\n",
    "x=data['clean_text']\n",
    "y=data['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "47eda58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retrieves unique values from the 'sentiment' column and stores them in 'unique_sentiments'\n",
    "\n",
    "unique_sentiments = y.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "051302eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replaces sentiment labels with numerical values: 'negative' -> 0, 'neutral' -> 1, 'positive' -> 2\n",
    "\n",
    "y = y.replace({'negative':0, 'neutral':1,'positive':2})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c41580",
   "metadata": {},
   "source": [
    "### Divide data into two parts: test and train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8a3c06e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train ,x_test, y_train , y_test = train_test_split(x,y, test_size=0.2, random_state=42 , stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8865d5fc",
   "metadata": {},
   "source": [
    "### Tokenizes the text data and converts it into sequences for training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "81557d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(x_train)\n",
    "x_train_seq = tokenizer.texts_to_sequences(x_train)\n",
    "x_test_seq = tokenizer.texts_to_sequences(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a352ab94",
   "metadata": {},
   "source": [
    "### Pads the tokenized sequences to ensure uniform length for training and testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6fbceba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "x_train_pad = pad_sequences(x_train_seq, maxlen = 100 ,padding='post')\n",
    "x_test_pad = pad_sequences(x_test_seq, maxlen = 100 ,padding='post')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc38b7a",
   "metadata": {},
   "source": [
    "### Encodes the sentiment labels into numerical values for training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f640f3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder=LabelEncoder()\n",
    "y_train_encoded=label_encoder.fit_transform(y_train)\n",
    "y_test_encoded=label_encoder.fit_transform(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a0cd8b4",
   "metadata": {},
   "source": [
    "### Converts the encoded labels into one-hot encoded format for training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "37f689af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import tensorflow as tf\n",
    "\n",
    "num_classes=len(unique_sentiments)\n",
    "y_train_onehot=tf.keras.utils.to_categorical(y_train_encoded,num_classes=num_classes)\n",
    "y_test_onehot=tf.keras.utils.to_categorical(y_test_encoded,num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa5a2cf6",
   "metadata": {},
   "source": [
    "### Create  Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "97cdd5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from tensorflow.keras.layers import Embedding,LSTM,Dense,Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d030dda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# Add the Embedding layer\n",
    "model.add(Embedding(input_dim=5000, output_dim=100,input_length=100))\n",
    "\n",
    "# Adds LSTM layer with 128 units and dropout\n",
    "model.add(LSTM(128, return_sequences=True, dropout=0.2))\n",
    "\n",
    "# Add the Flatten layer\n",
    "model.add(Flatten())\n",
    "\n",
    "# Add the Dropout layer\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# Add the Dense layer with 64 neurons and ReLU activation\n",
    "model.add(Dense(64, activation='relu'))\n",
    "\n",
    "# Add the output Dense layer with 3 neurons and softmax activation\n",
    "model.add(Dense(3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9643943d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiles the model with Adam optimizer, categorical cross-entropy loss, and accuracy metric\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8a77ada6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sets early stopping based on validation accuracy with patience of 4 epochs\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', patience=4, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d96f98c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m275/275\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 296ms/step - accuracy: 0.4057 - loss: 1.0841 - val_accuracy: 0.5383 - val_loss: 0.9362\n",
      "Epoch 2/50\n",
      "\u001b[1m275/275\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 446ms/step - accuracy: 0.5927 - loss: 0.8668 - val_accuracy: 0.6516 - val_loss: 0.7738\n",
      "Epoch 3/50\n",
      "\u001b[1m275/275\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 379ms/step - accuracy: 0.6826 - loss: 0.7367 - val_accuracy: 0.6686 - val_loss: 0.7489\n",
      "Epoch 4/50\n",
      "\u001b[1m275/275\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 413ms/step - accuracy: 0.7227 - loss: 0.6646 - val_accuracy: 0.6791 - val_loss: 0.7401\n",
      "Epoch 5/50\n",
      "\u001b[1m275/275\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 426ms/step - accuracy: 0.7368 - loss: 0.6346 - val_accuracy: 0.6889 - val_loss: 0.7196\n",
      "Epoch 6/50\n",
      "\u001b[1m275/275\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 421ms/step - accuracy: 0.7597 - loss: 0.6060 - val_accuracy: 0.6887 - val_loss: 0.7386\n",
      "Epoch 7/50\n",
      "\u001b[1m275/275\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 386ms/step - accuracy: 0.7765 - loss: 0.5728 - val_accuracy: 0.6866 - val_loss: 0.7339\n",
      "Epoch 8/50\n",
      "\u001b[1m275/275\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 391ms/step - accuracy: 0.7872 - loss: 0.5540 - val_accuracy: 0.6934 - val_loss: 0.7405\n",
      "Epoch 9/50\n",
      "\u001b[1m275/275\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 253ms/step - accuracy: 0.7955 - loss: 0.5283 - val_accuracy: 0.6912 - val_loss: 0.7534\n",
      "Epoch 10/50\n",
      "\u001b[1m275/275\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 281ms/step - accuracy: 0.8044 - loss: 0.5208 - val_accuracy: 0.6887 - val_loss: 0.8006\n",
      "Epoch 11/50\n",
      "\u001b[1m275/275\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 253ms/step - accuracy: 0.8098 - loss: 0.4991 - val_accuracy: 0.6841 - val_loss: 0.7822\n",
      "Epoch 12/50\n",
      "\u001b[1m275/275\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 310ms/step - accuracy: 0.8187 - loss: 0.4816 - val_accuracy: 0.6859 - val_loss: 0.8090\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2701057bdd0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Trains the model with early stopping and validation split of 20%\n",
    "\n",
    "model.fit(x_train_pad, y_train_onehot, epochs=50, batch_size=64,validation_split=0.2,callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e51d96af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 75ms/step\n"
     ]
    }
   ],
   "source": [
    "# Makes predictions on the test data and converts probabilities to class labels\n",
    "\n",
    "y_pred_probs = model.predict(x_test_pad)\n",
    "y_pred = np.argmax(y_pred_probs,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5405bad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.61      0.67      1556\n",
      "           1       0.63      0.77      0.69      2224\n",
      "           2       0.80      0.72      0.76      1717\n",
      "\n",
      "    accuracy                           0.71      5497\n",
      "   macro avg       0.73      0.70      0.71      5497\n",
      "weighted avg       0.72      0.71      0.71      5497\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Prints the classification report for the model's predictions on the test data\n",
    "\n",
    "from sklearn.metrics import confusion_matrix ,classification_report \n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd6d658",
   "metadata": {},
   "source": [
    "* Accuracy: 71% of the total predictions are correct.\n",
    "* Macro Average: Averages precision, recall, and F1-score across all classes equally (0.73, 0.70, 0.71).\n",
    "* Weighted Average: Averages metrics, weighted by the number of instances in each class (0.72, 0.71, 0.71)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b8916fb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 953  544   59]\n",
      " [ 276 1707  241]\n",
      " [  47  440 1230]]\n"
     ]
    }
   ],
   "source": [
    "# Prints the confusion matrix for the model's predictions on the test data\n",
    "\n",
    "print(confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5897c840",
   "metadata": {},
   "source": [
    "The model correctly classified 953 instances of class 0, but misclassified 544 instances as class 1 and 59 instances as class 2. Similarly, it correctly classified 1,707 instances of class 1, while 276 instances were misclassified as class 0 and 241 as class 2. For class 2, the model accurately classified 1,230 instances, with 47 instances misclassified as class 0 and 440 as class 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "264e2e6c",
   "metadata": {},
   "source": [
    "* The model performs best at identifying class 1 (1707 correct classifications).\n",
    "* Misclassifications are higher for class 0 being predicted as 1 and vice versa.\n",
    "* Class 2 has relatively fewer misclassifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f6ea3dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6e9552c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "# Saves the trained model to a file named 'sentiment_model2.h5'\n",
    "\n",
    "model.save(\"sentiment_model2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "233915ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saves the tokenizer object to a file named 'tokenizer.pickle' using pickle\n",
    "\n",
    "with open ('tokenizer.pickle','wb') as handle:\n",
    "    pickle.dump(tokenizer,handle,protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc4489d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
